{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import csv, random, time\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "from nltk.corpus.reader.wordnet import Synset,Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PropertyType(Enum):\n",
    "    LEX = 'lexical'\n",
    "    SEM = 'semantic'\n",
    "\n",
    "\n",
    "CONFIG = [\n",
    "    ('synonym', 'syn', lambda elem: [l for l in elem.synset().lemmas() if elem is not l], PropertyType.LEX),\n",
    "    ('antonym', 'ant', Lemma.antonyms, PropertyType.LEX),\n",
    "#     ('hypernym', 'hyper', Synset.hypernyms, PropertyType.SEM),\n",
    "    #('hyponym', 'hypo', Synset.hyponyms, PropertyType.SEM),\n",
    "#     ('holonym', 'holo', [Synset.member_holonyms, Synset.substance_holonyms, Synset.part_holonyms], PropertyType.SEM),\n",
    "    #('meronym', 'mero', [Synset.member_meronyms, Synset.substance_meronyms, Synset.part_meronyms], PropertyType.SEM),\n",
    "    #('causes', 'causes', Synset.causes, PropertyType.SEM),\n",
    "    #('entailment', 'entail', Synset.entailments, PropertyType.SEM),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouletteData:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.elems = [e for e in data]\n",
    "        self.weights = []\n",
    "        self.cums_weights = []\n",
    "        self._normalize_data()\n",
    "\n",
    "    def _normalize_data(self):\n",
    "        temp = 0\n",
    "        for elem in self.data:\n",
    "            self.weights.append(self.data[elem])\n",
    "            temp += self.data[elem]\n",
    "            self.cums_weights.append(temp)\n",
    "\n",
    "    def get_random_elements(self, k=1):\n",
    "        return random.choices(self.elems, cum_weights=self.cums_weights, k=k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_word(item):\n",
    "    temp = item.name().split('.')\n",
    "    return temp[1] if temp[0] is \"\" else temp[0]\n",
    "\n",
    "\n",
    "def _save_data(data, file='data', opener=None):\n",
    "    print(\"Saving in \" + file + \" file\")\n",
    "    with (open(file, 'w') if not opener else open(file, 'w', opener=opener)) as fd:\n",
    "        for t in data:\n",
    "            fd.write(\" \".join(map(lambda x: str(x), t)) + \"\\n\")\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "def _get_relative_triplets(prop_type, elem):\n",
    "    result = set()\n",
    "    elem_word = _get_word(elem)\n",
    "    for _, sym, func, _ in [c for c in CONFIG if c[3] is prop_type]:\n",
    "        func_list = func if isinstance(func, (list, tuple)) else [func] if callable(func) else []\n",
    "        for f in func_list:\n",
    "            words = [_get_word(e) for e in f(elem)]\n",
    "            for w in [e for e in words if e != elem_word]:\n",
    "                result.add((elem_word, sym, w))\n",
    "    return result\n",
    "\n",
    "\n",
    "def build_wordnet_triplets(save=False):\n",
    "    print(\"Extracting data\")\n",
    "    triplets = set()\n",
    "    for synset in wn.all_synsets():\n",
    "        triplets |= _get_relative_triplets(PropertyType.SEM, synset)\n",
    "        lemmas = [lem for lem in synset.lemmas()]\n",
    "        for lem in lemmas:\n",
    "            triplets |= _get_relative_triplets(PropertyType.LEX, lem)\n",
    "    print(\"Done!\")\n",
    "    if save:\n",
    "        _save_data(triplets)\n",
    "\n",
    "    return triplets\n",
    "\n",
    "\n",
    "def _init_word_stats():\n",
    "    temp = {}\n",
    "    for _, sym, _, _ in CONFIG:\n",
    "        temp[sym] = 0\n",
    "    return temp\n",
    "\n",
    "\n",
    "def _extract_stats(triplets):\n",
    "    rel_stats = {}\n",
    "    word_stats = {}\n",
    "\n",
    "    for w1, r, w2 in triplets:\n",
    "        if w1 not in rel_stats:\n",
    "            rel_stats[w1] = _init_word_stats()\n",
    "        if w2 not in rel_stats:\n",
    "            rel_stats[w2] = _init_word_stats()\n",
    "\n",
    "        word_stats[w1] = word_stats[w1]+1 if w1 in word_stats else 1\n",
    "        word_stats[w2] = word_stats[w2]+1 if w2 in word_stats else 1\n",
    "        rel_stats[w1][r] = rel_stats[w1][r]+1\n",
    "        rel_stats[w2][r] = rel_stats[w2][r]+1\n",
    "\n",
    "    return word_stats, rel_stats\n",
    "\n",
    "def build_noise(triplets, samples_pc=1, save=False):\n",
    "    word_stats, rel_stats = _extract_stats(triplets)\n",
    "    print(\"Building noise\")\n",
    "    noise = set()\n",
    "    samples_count = int(samples_pc * len(triplets))\n",
    "\n",
    "    words_generator = RouletteData(word_stats)\n",
    "    queue = None\n",
    "\n",
    "    while samples_count > 0:\n",
    "        if not queue or len(queue) is 0:\n",
    "            queue = deque(words_generator.get_random_elements(samples_count*2), maxlen=samples_count*2)\n",
    "        w1, w2 = queue.popleft(), queue.popleft()\n",
    "        rel = RouletteData(rel_stats[w1]).get_random_elements()[0]\n",
    "        if w1 != w2 and (w1, rel, w2) not in triplets and (w2, rel, w1) not in triplets:\n",
    "            noise.add((w1, rel, w2))\n",
    "            samples_count -= 1\n",
    "    print(\"Done!\")\n",
    "    if save:\n",
    "        _save_data(noise, 'data-noise')\n",
    "    return noise, len(word_stats)\n",
    "\n",
    "\n",
    "def _split_data(data, split):\n",
    "    print(\"Splitting data\")\n",
    "    rel_data = {}\n",
    "    for t in data:\n",
    "        if t[1] not in rel_data:\n",
    "            rel_data[t[1]] = []\n",
    "        rel_data[t[1]].append(t)\n",
    "    result = set()\n",
    "    for rel in rel_data:\n",
    "        random.shuffle(rel_data[rel])\n",
    "        count = int(split * len(rel_data[rel]))\n",
    "        result |= set(rel_data[rel][:count])\n",
    "    print('Done!')\n",
    "    return result\n",
    "\n",
    "\n",
    "def _get_checked_items(data, val):\n",
    "    return list(map(lambda x: x+(val,), data))\n",
    "\n",
    "\n",
    "def _dic_to_sorted_tuple(dic):\n",
    "    result = [(dic[k], k) for k in dic]\n",
    "    result.sort()\n",
    "    return result\n",
    "\n",
    "def _save_csv_data(data, file):\n",
    "    with open(file, 'w', newline='') as fd:\n",
    "        writer = csv.writer(fd)\n",
    "        for t in data:\n",
    "            writer.writerow(t)\n",
    "\n",
    "\n",
    "def _get_final_items(data):\n",
    "    print(\"Getting final items\")\n",
    "    rels_ids = {}\n",
    "    i = 0\n",
    "    for _, sym, _, _ in CONFIG:\n",
    "        rels_ids[sym] = i\n",
    "        i += 1\n",
    "    _save_csv_data(_dic_to_sorted_tuple(rels_ids), str(total_words) + '.rels.csv')\n",
    "    i = 0\n",
    "    words_ids = {}\n",
    "    triplets = []\n",
    "    for w1, r, w2, v in data:\n",
    "        if w1 not in words_ids:\n",
    "            words_ids[w1] = i\n",
    "            i += 1\n",
    "        if w2 not in words_ids:\n",
    "            words_ids[w2] = i\n",
    "            i += 1\n",
    "        triplets.append((words_ids[w1], rels_ids[r], words_ids[w2], v))\n",
    "    _save_csv_data(_dic_to_sorted_tuple(words_ids), str(total_words) + '.words.csv')\n",
    "    print('Done!')\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Build all WordNet triplets\n",
    "temp = build_wordnet_triplets()\n",
    "# _save_data(temp, 'real-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "SPLIT=.5\n",
    "real_data = _split_data(temp, SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building noise\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Build noise from splitted data stats\n",
    "NOISE_PC=1\n",
    "false_data, total_words = build_noise(real_data, NOISE_PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting final items\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Items to numbers\n",
    "data = _get_final_items(_get_checked_items(real_data, 1) + _get_checked_items(false_data, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling data\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Shuffle final data\n",
    "print(\"Shuffling data\")\n",
    "random.shuffle(data)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving in 98987.set file\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Save data to file\n",
    "if total_words:\n",
    "    _save_data(data, str(total_words) + '.set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
