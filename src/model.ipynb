{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryan/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Reshape, Dot, Activation, Flatten, BatchNormalization\n",
    "from keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "WORDS_COUNT = 133778\n",
    "EMB_OUT_DIM = 32\n",
    "REL_COUNT = 8\n",
    "\n",
    "# Input\n",
    "input_words_1 = Input(shape=(1,), dtype='int32', name='input_words_1')\n",
    "input_words_2 = Input(shape=(1,), dtype='int32', name='input_words_2')\n",
    "input_rels = Input(shape=(1,), dtype='int32', name='input_rels')\n",
    "\n",
    "# Embeddings\n",
    "words_emb_layer = Embedding(input_dim=WORDS_COUNT, output_dim=EMB_OUT_DIM)\n",
    "words_emb_1 = words_emb_layer(input_words_1)\n",
    "words_emb_2 = words_emb_layer(input_words_2)\n",
    "\n",
    "rels_emb = Embedding(input_dim=REL_COUNT, output_dim=EMB_OUT_DIM**2, input_length=1)(input_rels)\n",
    "\n",
    "# Reshape Relations Embedding\n",
    "rels_matrix = Reshape(target_shape=(EMB_OUT_DIM, EMB_OUT_DIM))(rels_emb)\n",
    "\n",
    "# Merge\n",
    "dot_w1_rel = Dot(axes=2)([words_emb_1, rels_matrix])\n",
    "dot_w1_rel_w2 = Dot(axes=2)([dot_w1_rel, words_emb_2])\n",
    "\n",
    "# Transpose result\n",
    "dot_result = Reshape(target_shape=(1,))(dot_w1_rel_w2)\n",
    "\n",
    "# Output\n",
    "output_layer = Activation(activation='sigmoid')(dot_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Model(inputs=[input_words_1, input_words_2, input_rels], outputs=[output_layer])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = []\n",
    "W2 = []\n",
    "R = []\n",
    "Y = []\n",
    "\n",
    "with open(str(WORDS_COUNT) + \".set\") as fp:\n",
    "    for line in fp:\n",
    "        w1, r, w2, y = line.split()\n",
    "        W1.append([w1])\n",
    "        W2.append([w2])\n",
    "        R.append([r])\n",
    "        Y.append([y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.asarray(W1)\n",
    "W2 = np.asarray(W2)\n",
    "R = np.asarray(R)\n",
    "Y = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger, Callback\n",
    "import csv\n",
    "\n",
    "class BatchHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.bla=[]\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.bla.append((batch, logs.get('loss'), logs.get('acc')))\n",
    "    \n",
    "    def on_train_end(self, logs={}):\n",
    "        FILE='batch.logs.csv'\n",
    "        np.savetxt(FILE, self.bla, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422976 samples, validate on 105744 samples\n",
      "Epoch 1/3\n",
      "422976/422976 [==============================] - 1417s 3ms/step - loss: 0.6828 - acc: 0.5508 - val_loss: 0.6595 - val_acc: 0.6042\n",
      "Epoch 2/3\n",
      "422976/422976 [==============================] - 1479s 3ms/step - loss: 0.4489 - acc: 0.8452 - val_loss: 0.6991 - val_acc: 0.6321\n",
      "Epoch 3/3\n",
      "422976/422976 [==============================] - 1479s 3ms/step - loss: 0.1697 - acc: 0.9502 - val_loss: 0.9226 - val_acc: 0.6371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9ce393a9e8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS=3\n",
    "#callbacks\n",
    "\n",
    "csv_logger = CSVLogger('training.log')\n",
    "batch_hist = BatchHistory()\n",
    "model.fit(x=[W1,W2,R], y=Y, batch_size=32, epochs=EPOCHS, validation_split=.2, callbacks=[csv_logger, batch_hist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"{0} [{1}].hd5\".format(WORDS_COUNT, EPOCHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
